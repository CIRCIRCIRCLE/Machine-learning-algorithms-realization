{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Multivariate Regression(GD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we are going to implement multivariate regression(gradient descent version). In particular, you will have to:\n",
    "\n",
    "* Complete the function `cost_function` to implement cost function for multivariate regression(gradient descent version) algorithm.\n",
    "* Complete the function `GDmultiLinparamEstimates` to implement multivariate regression(gradient descent version) algorithm.\n",
    "\n",
    "Note we do not cover single value linear regression (gradient descent version) in this experiment as it is a similar one. You can play with it yourselves after going through this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The required libraries for this notebook are pandas, sklearn and numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import pandas\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data\n",
    "The data we are using is from ***multi_regr_data.csv***. It consists of 1000 data related to student marks. Each data point has 3 columns(marks) and we are going to use all of them for multivariate linear regression. In particular, we will use the first 2 marks to predict the 3rd mark.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 3)\n"
     ]
    }
   ],
   "source": [
    "# Loading the CSV file\n",
    "dataset=pandas.read_csv('./multi_regr_data.csv')\n",
    "print(dataset.shape) #(data_number,feature_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data, we will use first 2 columns as features and the 3rd columns as target.\n",
    "X = dataset[list(dataset.columns)[:-1]]\n",
    "Y = dataset[list(dataset.columns)[-1]] \n",
    "\n",
    "# As pointed out in previous lab, we need to add a constant feature\n",
    "intercept=np.ones((X.shape[0],1))\n",
    "X=np.concatenate((intercept,X),axis=1)\n",
    "\n",
    "# Split the data into training and testing(75% training and 25% testing data)\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(X, Y, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize using Gradient Descent Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cost function is defined as follows:\n",
    "\\begin{align}\n",
    "J\\left(\\beta \\right) & =  {\\frac{1}{2n}}\\sum_{i=1}^n \\left(y_i - \\hat{y_i} \\right)^2\\\\\n",
    "\\end{align}\n",
    "or \n",
    "\\begin{align}\n",
    "J\\left(\\beta \\right) & =  {\\frac{1}{2n}}SSR\\left(y_i,\\hat{y_i} \\right)\\end{align}\n",
    "\n",
    "You are asked to implement this cost function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2470.11\n"
     ]
    }
   ],
   "source": [
    "def cost_function(X, Y, beta):\n",
    "    # implement cost function here\n",
    "    n=X.shape[0]\n",
    "    J = np.sum((X.dot(beta) - Y) ** 2)/(2 * n)\n",
    "    return J\n",
    "\n",
    "\n",
    "# initialize B, all the beta values are set as 0.\n",
    "beta= np.zeros(3, dtype=float)\n",
    "\n",
    "# cal initial cost\n",
    "inital_cost = cost_function(X, Y, beta)\n",
    "print(inital_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradient Descent Steps:**\n",
    "1. Initialize values: \\begin{align}\\beta_0,\\beta_1,…,\\beta_n\\end{align}  It is suggested you initilize with 0.\n",
    "2. Iteratively update, until convergence: \\begin{align} β_j : =  β_j - \\alpha {\\frac{\\partial}{\\partial J\\left(\\beta_j \\right) }}J\\left(\\beta \\right) \\\\ \\end{align}  α: learning rate.\n",
    "\n",
    "**Hint:** Step 2 function can also be written as \\begin{align} β_j : =  β_j - \\alpha \\frac{1}{n}\\sum_{i=1}^n \\left(\\hat{y_i} - y_i \\right)x_{ij}\\\\ \\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.47889172  0.09137252  0.90144884]\n",
      "10.475123473539167\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def GDmultiLinparamEstimates(X, Y, beta, learning_rate, iterations):\n",
    "    cost_history = [0] * iterations\n",
    "    n = X.shape[0]\n",
    "    \n",
    "    for iteration in range(iterations):\n",
    "        #  complete the code below.   \n",
    "        # Hypothesis Values\n",
    "        loss = X.dot(beta)-Y\n",
    "        # Gradient Calculation\n",
    "        gradient = X.T.dot(loss)\n",
    "        # Changing Values of beta using Gradient\n",
    "        beta = beta - learning_rate * gradient/ n\n",
    "        \n",
    "        cost = cost_function(X, Y, beta)\n",
    "        cost_history[iteration] = cost\n",
    "        \n",
    "    return beta, cost_history\n",
    "\n",
    "iterations = 100000 # a value of iteration\n",
    "learning_rate = 0.0001 # alpha\n",
    "\n",
    "\n",
    "\n",
    "# run your algorithm\n",
    "newB, cost_history = GDmultiLinparamEstimates(X, Y, beta, learning_rate, iterations)\n",
    "\n",
    "# New Values of B\n",
    "print(newB)\n",
    "# Final Cost of new B\n",
    "print(cost_history[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final hypothesis for the whole dataset (i.e. X and Y as defined above) should be:\n",
    "\\begin{align}\n",
    "y & = -0.47889172 + 0.09137252*x_1 + 0.90144884*x_2\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the true target:  25\n",
      "We predict as:  20.603310452986506\n",
      "Overall Accuracy Score from library implementation: 0.9112675801400184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Software\\conda\\lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "d:\\Software\\conda\\lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "d:\\Software\\conda\\lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "d:\\Software\\conda\\lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    }
   ],
   "source": [
    "def multilinearRegrPredict(xtrain, ytrain,xtest):\n",
    "    reg=LinearRegression()\n",
    "    reg.fit(xtrain, ytrain)\n",
    "    y_pred = reg.predict(xtest)\n",
    "    print('For the true target: ',list(ytest)[-1])\n",
    "    print('We predict as: ', list(y_pred)[-1]) # print out the \n",
    "    print(\"Overall Accuracy Score from library implementation:\", reg.score(xtest, ytest)) #.score(Predicted value, Y axis of Test data) methods returns the Accuracy Score or how much percentage the predicted value and the actual value matches\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "y_pred = multilinearRegrPredict(xtrain, ytrain, xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimatedB, trainingcost = GDmultiLinparamEstimates(xtrain, ytrain, beta, 0.0001, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction of last item 20.603310452986506\n"
     ]
    }
   ],
   "source": [
    "y_pred1 = xtest.dot(estimatedB)\n",
    "print(\"The prediction of last item\",y_pred[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
